<img src="images/logo.png" alt="Т Банк Лого" width="200" align="right" />

# Классификация отзывов с маркетплейсов с помощью LLM

## Буду очень признателен, если напишите ошибки в моем решении. (__matveytizhin@gmail.com__)
## 1. Описание Задания и Требований

### Цель кейса

Научить LLM-модель классифицировать отзывы с маркетплейсов по категориям товаров, к которым они относятся.

### Критерии успешности:
*   Модель должна как можно лучше классифицировать тестовые отзывы по заданным категориям.
*   Время классификации одного примера не должно превышать `5` секунд.
*   Оценка качества производится по метрике `Weighted F1`, включая класс "нет товара".

### Ограничения
*   Запрещено использовать **внешние API** (например, ChatGPT, DeepSeek и т.д.).
*   Запрещено использовать тестовую выборку для обучения или валидации.
*   Решение должно **умещаться в ресурсы Google Colab** (16GB VRAM T4).
*   Запрещена ручная разметка, но разрешена **генерация синтетических данных на основе выданных**.

---

## 2. Реализация и Объяснение Подхода

Для решения задачи был разработан многоэтапный пайплайн, который включает автоматическую разметку данных с помощью **открытой модели `Qwen/Qwen2.5-7B-Instruct`**, **генерацию синтетических данных** для балансировки классов и дообучение (fine-tuning) компактной BERT-модели для итоговой классификации.

### Этап 1: Автоматическая разметка данных (Prompt Engineering)

Поскольку исходный обучающий датасет `X_train.csv` не имел меток, для его разметки была использована открытая модель **`Qwen/Qwen2.5-7B-Instruct`** в 4-битном режиме квантизации. Ключевым элементом этого этапа стал продвинутый **промпт-инжиниринг**, где модели был дан строгий пошаговый алгоритм:

1.  **Поиск явного упоминания товара:** Если в отзыве есть товар из справочника (например, "рюкзак", "платье"), категория присваивается немедленно, игнорируя остальной контекст (доставка, споры).
2.  **Поиск физического описания:** Если товар не найден, выполняется поиск описания дефекта или характеристик ("рукава короткие", "не включается").
3.  **Категория "нет товара":** Присваивается только в случае, если первые два шага не дали результата.

*Промпт был усилен примерами и принципами для сложных случаев, например: "ужасная синтетика" -> "нет товара" (мало информации для однозначной классификации), но "низ рваный" -> "одежда" (подразумеваются джинсы или платье).*

В результате был получен размеченный, но сильно несбалансированный датасет.

### Этап 2: Генерация синтетических данных

Размеченный на первом этапе датасет имел сильный перекос в сторону категорий "одежда" и "нет товара", что могло привести к низкой производительности модели на редких классах. Для решения этой проблемы была проведена **генерация синтетических данных** для всех миноритарных классов с помощью той же модели `Qwen/Qwen2.5-7B-Instruct`.

**В качестве отправной точки для генерации новых данных послужила категория "одежда"**, так как она была самой многочисленной и содержала разнообразные и качественные примеры отзывов, которые можно было использовать для имитации стиля реальных пользователей.

**Методология генерации:**
-   **Стиль:** Модели предоставлялись случайные отзывы из категории "одежда" для имитации лексики и манеры письма.
-   **Содержание:** Задавался конкретный товар (например, "кастрюля"), целевая категория ("посуда") и сценарий отзыва (позитивный, негативный, жалоба на сервис).
-   **Правила:** Использовался тот же промпт с правилами, что и на этапе разметки, чтобы сгенерированные отзывы были "идеальными" примерами для обучения.

В результате был создан финальный сбалансированный датасет `df_balanced_train.csv`.

### Этап 3: Дообучение финальной модели (Fine-Tuning)

Модель `Qwen/Qwen2.5-7B-Instruct` слишком велика и медленна для выполнения требования по скорости инференса (< 5 секунд). Поэтому для финальной классификации была выбрана более легкая и быстрая модель — **`DeepPavlov/rubert-base-cased`**. Эта BERT-модель была дообучена (full fine-tuning) на сбалансированном датасете, полученном на предыдущих этапах.

**Процесс обучения:**
-   **Данные:** Датасет `df_balanced_train.csv` был разделен на обучающую и валидационную выборки (80/20).
-   **Обучение:** Модель обучалась 7 эпох. Лучшая модель сохранялась на основе метрики `Weighted F1-score`.

В итоге была получена быстрая, компактная и качественная модель для классификации.

---

## 3. Описание Полученной Модели

Финальная модель — это дообученная версия **`DeepPavlov/rubert-base-cased`**, которая демонстрирует следующие характеристики:

-   **Качество на валидации:** **0.86** Weighted F1-score (метрика F1-score здесь получена путем сравнения предсказаний модели с синтетическими метками, сгенерированными на первом этапе. Если эти сгенерированные метки содержат ошибки, то и F1-score будет неинформативным. Так по итогу и получилось, несмотря на хорошее качество на валидации,  на некоторых простых примерах, модель определяет неправильно категорию, потому что в самом датасете эти подобные примеры были неправильным образом размечены. На исправление данной проблемы, к сожалению, времени не осталось) 
-   **Скорость инференса:** **0.064 секунды** на отзыв, что значительно быстрее требуемых 5 секунд.
-   **Размер на диске:** **684 Мб**, что позволяет легко использовать модель в средах с ограниченными ресурсами.
-   **Поведение:** Модель уверенно классифицирует отзывы, где категория явно указана, а также хорошо справляется с нетривиальными случаями, где категория определяется по контексту.
-   **Развертывание:** Все параметры модели сохранены в архиве `final_rubert_classifier.zip`. Модель также загружена на Hugging Face Hub и готова к использованию через `pipeline`.

<img width="741" height="587" alt="image" src="https://github.com/user-attachments/assets/14d1fb3b-eae9-40a2-ab45-4f92431f857f" />

---

## 4. Структура Репозитория

Репозиторий организован по принципу "один ноутбук — один этап решения".

-   `nlp_case_sirius_t_bank_main.ipynb`: **[Основной ноутбук]** Первоначальный ноутбук, в котором описываются основные моменты решения и поставленная задача.
-   `data_markup_QWEN.ipynb`: **[ЭТАП 1]** Ноутбук для автоматической разметки исходного датасета `X_train.csv` с использованием `Qwen/Qwen2.5-7B-Instruct`.
-   `data_generation_qwen.ipynb`: **[ЭТАП 2]** Ноутбук для генерации синтетических данных с целью балансировки классов.
-   `fully_fine_tunning.ipynb`: **[ЭТАП 3 и 4]** Ключевой ноутбук, который выполняет дообучение финальной модели `rubert-base-cased`, оценки её качества и генерации итогового сабмишена.

-   `final_rubert_classifier.zip`: Архив с файлами дообученной модели, готовой к использованию (отслеживается через Git LFS).
-   `predictions_test.csv`: **Итоговый файл** с предсказанными категориями для тестовой выборки.
-   `X_test_fully_with_predictions.csv`: Тестовые данные с предсказаниями и скорами уверенности модели (для анализа).
-   `.gitattributes`: Файл конфигурации Git для работы с большими файлами (Git LFS).
-   `datasets_archive/`: Папка с архивом всех промежуточных и итоговых датасетов, полученных в ходе работы:
    -   `X_train.csv`, `X_test.csv`: Исходные неразмеченные данные.
    -   `saiga_mistral_7b_df_train.csv`: Промежуточные результаты разметки моделью `saiga_mistral`.
    -   `qwen2.5-7B_instruct_df_train_v*.csv`: Промежуточные результаты разметки моделью `Qwen` с разными версиями промпта.
    -   `dataset_*.csv` (dishes, shoes, и т.д.): Синтетически сгенерированные данные для каждой миноритарной категории.
    -   `df_balanced_train.csv`: Итоговый сбалансированный датасет для обучения.
    -   `y_true.csv`, `y_mistral.csv`: Различные версии меток, использовавшиеся для анализа и сравнения (были получены с помощью `saiga_mistral` на разных этапах работы).
-   `images/`: Папка с изображениями для `README.md`.

---
<br>

| Т-Банк | Т-Образование | Университет Сириус |
|:---:|:---:|:---:|
| <img src="images/bank-building.jpg" width="250"> | <img src="images/t-obrazovanie.jpg" width="250"> | <img src="images/university-sirius.jpg" width="250"> |
