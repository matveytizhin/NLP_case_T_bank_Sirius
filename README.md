# Классификация отзывов с маркетплейсов с помощью LLM

## 1. Описание Задания и Требований

### Цель кейса

Научить LLM-модель классифицировать отзывы с маркетплейсов по категориям товаров, к которым они относятся.

### Критерии успешности:
*   Модель должна как можно лучше классифицировать тестовые отзывы по заданным категориям.
*   Время классификации одного примера не должно превышать `5` секунд.
*   Оценка качества производится по метрике `Weighted F1`, включая класс "нет товара".

### Ограничения
*   Запрещено использовать **внешние API** (например, ChatGPT, DeepSeek и т.д.) для решения задачи или разметки данных.
*   Запрещено использовать тестовую выборку для обучения или валидации.
*   Решение должно **умещаться в ресурсы Google Colab** (16GB VRAM T4).
*   Запрещено использовать **внешние данные** для обучения, но разрешена **генерация синтетических данных на основе выданных**.

---

## 2. Реализация и Объяснение Подхода

Для решения задачи был разработан многоэтапный пайплайн, который включает автоматическую разметку данных с помощью **открытой модели `Qwen/Qwen2.5-7B-Instruct`**, **генерацию синтетических данных на основе выданных** для балансировки классов и дообучение (fine-tuning) компактной и быстрой BERT-модели для итоговой классификации.

### Этап 1: Автоматическая разметка данных (Prompt Engineering)

**Проблема:** Исходный обучающий датасет `X_train.csv` не имел меток категорий. Ручная разметка была запрещена.

**Решение:** Для создания качественного обучающего набора была использована открытая модель `Qwen/Qwen2.5-7B-Instruct`, запущенная в 4-битном режиме квантизации для экономии ресурсов. Ключевым элементом этого этапа стал продвинутый **промпт-инжиниринг**.

**Логика промпта для разметки:**
-   **Строгий алгоритм принятия решений:** Модели был дан четкий пошаговый алгоритм:
    1.  **Поиск явного упоминания товара:** Сначала модель ищет в отзыве конкретный товар из предоставленного справочника (например, "рюкзак", "платье"). Если товар найден, категория присваивается немедленно, игнорируя остальной контекст (проблемы с доставкой, споры).
    2.  **Поиск физического описания:** Если товар не найден, модель ищет описание дефекта или характеристик ("рукава короткие", "не включается").
    3.  **Категория "нет товара":** Только если первые два шага не дали результата, присваивается категория "нет товара".
-   **Принципы и примеры:** Промпт был усилен главными принципами классификации и большим количеством примеров (включая негативные), чтобы модель лучше понимала логику в сложных случаях (например, "ужасная синтетика" -> "нет товара", но "низ рваный" -> "одежда").

*Изначально была предпринята попытка использовать модель `saiga_mistral_7b`, но она показала низкое качество понимания русского языка. Модель `Qwen`, изначально обученная на большом корпусе русскоязычных текстов, справилась с задачей значительно лучше.*

**Результат этапа:** Размеченный набор данных, который, однако, показал сильный дисбаланс классов в сторону категорий "одежда" и "нет товара".

### Этап 2: Генерация синтетических данных для миноритарных классов

**Проблема:** Размеченный на первом этапе датасет имел сильный перекос в сторону категорий "одежда" и "нет товара". Обучение на таких данных привело бы к низкой производительности на редких классах.

**Решение:** Была проведена **генерация синтетических данных на основе выданных** для всех миноритарных классов (`бытовая техника`, `электроника`, `посуда` и др.) с помощью той же открытой модели `Qwen/Qwen2.5-7B-Instruct`.

**Методология генерации:**
-   **Разделение стиля и содержания:** Для генерации реалистичных отзывов модели предоставлялись:
    -   **Примеры стиля:** Случайные отзывы из категории "одежда" для имитации лексики и манеры реальных пользователей.
    -   **Задача на содержание:** Конкретный товар (например, "кастрюля"), целевая категория ("посуда") и сценарий (позитивный, негативный, жалоба на сервис).
    -   **Правила:** Тот же промпт с правилами, что и на этапе разметки, чтобы сгенерированные отзывы были "идеальными" примерами для этих правил.

**Результат этапа:** Созданы сбалансированные датасеты для каждого миноритарного класса. Эти файлы были объединены для создания финального обучающего набора данных `df_balanced_train.csv`.

### Этап 3: Дообучение финальной модели (Fine-Tuning)

**Проблема:** Открытая модель `Qwen/Qwen2.5-7B-Instruct` слишком велика и медленна для выполнения требования по скорости инференса (< 5 секунд на отзыв).

**Решение:** Была выбрана значительно более легкая и быстрая модель — **`DeepPavlov/rubert-base-cased`**. Эта BERT-подобная модель была дообучена (full fine-tuning) на качественном, сбалансированном датасете, полученном на предыдущих этапах.

**Процесс обучения:**
-   **Подготовка данных:** Датасет `df_balanced_train.csv` был разделен на обучающую и валидационную выборки (80/20).
-   **Обучение:** Модель обучалась в течение 7 эпох. Лучшая модель сохранялась на основе метрики `Weighted F1-score` на валидационной выборке.

**Результат этапа:** Сохраненная дообученная модель `final_rubert_classifier`, которая является быстрой, компактной и показывает высокое качество классификации.

---

## 3. Описание Полученной Модели

Финальная модель — это дообученная версия **`DeepPavlov/rubert-base-cased`**, которая демонстрирует следующие характеристики:

-   **Качество на валидации:** **0.86** Weighted F1-score.
-   **Скорость инференса:** **0.064 секунды** на отзыв, что значительно быстрее требуемых 5 секунд.
-   **Размер на диске:** **684 Мб**, что позволяет легко использовать модель даже в средах с ограниченными ресурсами.
-   **Поведение:** Модель уверенно классифицирует отзывы, где категория явно указана, а также хорошо справляется с нетривиальными случаями, где категория определяется по контексту и описанию, а не по прямому упоминанию товара.
-   **Развертывание:** Все параметры модели сохранены в архиве `final_rubert_classifier.zip`. Модель также загружена на Hugging Face Hub и готова к использованию через `pipeline`.

<img width="741" height="608" alt="image" src="https://github.com/user-attachments/assets/20376b84-b106-4bd0-9912-2688db1e2fbf" />


---

## 4. Структура Репозитория

Репозиторий организован по принципу "один ноутбук — один этап решения".

-   `nlp_case_sirius_t_bank_main.ipynb`: **[Основной ноутбук]** Первоначальный ноутбук, в котором описываются основные моменты решения и поставленная задача.
-   `data_markup_QWEN.ipynb`: **[ЭТАП 1]** Ноутбук для автоматической разметки исходного датасета `X_train.csv` с использованием `Qwen/Qwen2.5-7B-Instruct`.
-   `data_generation_qwen.ipynb`: **[ЭТАП 2]** Ноутбук для генерации синтетических данных с целью балансировки классов.
-   `fully_fine_tunning_qwen2-5-7b_instruct.ipynb`: **[ЭТАП 3 и 4]** Ключевой ноутбук, который выполняет дообучение финальной модели `rubert-base-cased`, оценки её качества и генерации итогового сабмишена.

-   `final_rubert_classifier.zip`: Архив с файлами дообученной модели, готовой к использованию (отслеживается через Git LFS).
-   `predictions_test.csv`: **Итоговый файл** с предсказанными категориями для тестовой выборки.
-   `X_test_fully_with_predictions.csv`: Тестовые данные с предсказаниями и скорами уверенности модели (для анализа).
-   `.gitattributes`: Файл конфигурации Git для работы с большими файлами (Git LFS).
-   `datasets_archive/`: Папка с архивом всех промежуточных и итоговых датасетов, полученных в ходе работы:
    -   `X_train.csv`, `X_test.csv`: Исходные неразмеченные данные.
    -   `saiga_mistral_7b_df_train.csv`: Промежуточные результаты разметки моделью `saiga_mistral`.
    -   `qwen2.5-7B_instruct_df_train_v*.csv`: Промежуточные результаты разметки моделью `Qwen` с разными версиями промпта.
    -   `dataset_*.csv` (dishes, shoes, и т.д.): Синтетически сгенерированные данные для каждой миноритарной категории.
    -   `df_balanced_train.csv`: Итоговый сбалансированный датасет для обучения.
    -   `y_true.csv`, `y_mistral.csv`: Различные версии меток, использовавшиеся для анализа и сравнения (были получены с помощью saiga_mistral на разных этапах работы)
