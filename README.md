<img src="data:image/jpeg;base64,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" alt="Tinkoff Bank Logo" width="200" align="right" />

# Классификация отзывов с маркетплейсов с помощью LLM

## 1. Описание Задания и Требований


### Цель кейса

Научить LLM-модель классифицировать отзывы с маркетплейсов по категориям товаров, к которым они относятся.

### Критерии успешности:
*   Модель должна как можно лучше классифицировать тестовые отзывы по заданным категориям.
*   Время классификации одного примера не должно превышать `5` секунд.
*   Оценка качества производится по метрике `Weighted F1`, включая класс "нет товара".

### Ограничения
*   Запрещено использовать **внешние API** (например, ChatGPT, DeepSeek и т.д.) для решения задачи или разметки данных.
*   Запрещено использовать тестовую выборку для обучения или валидации.
*   Решение должно **умещаться в ресурсы Google Colab** (16GB VRAM T4).
*   Запрещено использовать **внешние данные** для обучения, но разрешена **генерация синтетических данных на основе выданных**.

---

## 2. Реализация и Объяснение Подхода

Для решения задачи был разработан многоэтапный пайплайн, который включает автоматическую разметку данных с помощью **открытой модели `Qwen/Qwen2.5-7B-Instruct`**, **генерацию синтетических данных на основе выданных** для балансировки классов и дообучение (fine-tuning) компактной и быстрой BERT-модели для итоговой классификации.

### Этап 1: Автоматическая разметка данных (Prompt Engineering)

**Проблема:** Исходный обучающий датасет `X_train.csv` не имел меток категорий. Ручная разметка была запрещена.

**Решение:** Для создания качественного обучающего набора была использована открытая модель `Qwen/Qwen2.5-7B-Instruct`, запущенная в 4-битном режиме квантизации для экономии ресурсов. Ключевым элементом этого этапа стал продвинутый **промпт-инжиниринг**.

**Логика промпта для разметки:**
-   **Строгий алгоритм принятия решений:** Модели был дан четкий пошаговый алгоритм:
    1.  **Поиск явного упоминания товара:** Сначала модель ищет в отзыве конкретный товар из предоставленного справочника (например, "рюкзак", "платье"). Если товар найден, категория присваивается немедленно, игнорируя остальной контекст (проблемы с доставкой, споры).
    2.  **Поиск физического описания:** Если товар не найден, модель ищет описание дефекта или характеристик ("рукава короткие", "не включается").
    3.  **Категория "нет товара":** Только если первые два шага не дали результата, присваивается категория "нет товара".
-   **Принципы и примеры:** Промпт был усилен главными принципами классификации и большим количеством примеров (включая негативные), чтобы модель лучше понимала логику в сложных случаях (например, "ужасная синтетика" -> "нет товара", но "низ рваный" -> "одежда").

*Изначально была предпринята попытка использовать модель `saiga_mistral_7b`, но она показала низкое качество понимания русского языка. Модель `Qwen`, изначально обученная на большом корпусе русскоязычных текстов, справилась с задачей значительно лучше.*

**Результат этапа:** Размеченный набор данных, который, однако, показал сильный дисбаланс классов в сторону категорий "одежда" и "нет товара".

### Этап 2: Генерация синтетических данных для миноритарных классов

**Проблема:** Размеченный на первом этапе датасет имел сильный перекос в сторону категорий "одежда" и "нет товара". Обучение на таких данных привело бы к низкой производительности на редких классах.

**Решение:** Была проведена **генерация синтетических данных на основе выданных** для всех миноритарных классов (`бытовая техника`, `электроника`, `посуда` и др.) с помощью той же открытой модели `Qwen/Qwen2.5-7B-Instruct`.

**Методология генерации:**
-   **Разделение стиля и содержания:** Для генерации реалистичных отзывов модели предоставлялись:
    -   **Примеры стиля:** Случайные отзывы из категории "одежда" для имитации лексики и манеры реальных пользователей.
    -   **Задача на содержание:** Конкретный товар (например, "кастрюля"), целевая категория ("посуда") и сценарий (позитивный, негативный, жалоба на сервис).
    -   **Правила:** Тот же промпт с правилами, что и на этапе разметки, чтобы сгенерированные отзывы были "идеальными" примерами для этих правил.

**Результат этапа:** Созданы сбалансированные датасеты для каждого миноритарного класса. Эти файлы были объединены для создания финального обучающего набора данных `df_balanced_train.csv`.

### Этап 3: Дообучение финальной модели (Fine-Tuning)

**Проблема:** Открытая модель `Qwen/Qwen2.5-7B-Instruct` слишком велика и медленна для выполнения требования по скорости инференса (< 5 секунд на отзыв).

**Решение:** Была выбрана значительно более легкая и быстрая модель — **`DeepPavlov/rubert-base-cased`**. Эта BERT-подобная модель была дообучена (full fine-tuning) на качественном, сбалансированном датасете, полученном на предыдущих этапах.

**Процесс обучения:**
-   **Подготовка данных:** Датасет `df_balanced_train.csv` был разделен на обучающую и валидационную выборки (80/20).
-   **Обучение:** Модель обучалась в течение 7 эпох. Лучшая модель сохранялась на основе метрики `Weighted F1-score` на валидационной выборке.

**Результат этапа:** Сохраненная дообученная модель `final_rubert_classifier`, которая является быстрой, компактной и показывает высокое качество классификации.

---

## 3. Описание Полученной Модели

Финальная модель — это дообученная версия **`DeepPavlov/rubert-base-cased`**, которая демонстрирует следующие характеристики:

-   **Качество на валидации:** **0.86** Weighted F1-score(проверяется на сгенерированных метках, поэтому может не совпадать с действительностью)
-   **Скорость инференса:** **0.064 секунды** на отзыв, что значительно быстрее требуемых 5 секунд.
-   **Размер на диске:** **684 Мб**, что позволяет легко использовать модель даже в средах с ограниченными ресурсами.
-   **Поведение:** Модель уверенно классифицирует отзывы, где категория явно указана, а также хорошо справляется с нетривиальными случаями, где категория определяется по контексту и описанию, а не по прямому упоминанию товара.
-   **Развертывание:** Все параметры модели сохранены в архиве `final_rubert_classifier.zip`. Модель также загружена на Hugging Face Hub и готова к использованию через `pipeline`.

<img width="741" height="587" alt="image" src="https://github.com/user-attachments/assets/14d1fb3b-eae9-40a2-ab45-4f92431f857f" />



---

## 4. Структура Репозитория

Репозиторий организован по принципу "один ноутбук — один этап решения".

-   `nlp_case_sirius_t_bank_main.ipynb`: **[Основной ноутбук]** Первоначальный ноутбук, в котором описываются основные моменты решения и поставленная задача.
-   `data_markup_QWEN.ipynb`: **[ЭТАП 1]** Ноутбук для автоматической разметки исходного датасета `X_train.csv` с использованием `Qwen/Qwen2.5-7B-Instruct`.
-   `data_generation_qwen.ipynb`: **[ЭТАП 2]** Ноутбук для генерации синтетических данных с целью балансировки классов.
-   `fully_fine_tunning_qwen2-5-7b_instruct.ipynb`: **[ЭТАП 3 и 4]** Ключевой ноутбук, который выполняет дообучение финальной модели `rubert-base-cased`, оценки её качества и генерации итогового сабмишена.

-   `final_rubert_classifier.zip`: Архив с файлами дообученной модели, готовой к использованию (отслеживается через Git LFS).
-   `predictions_test.csv`: **Итоговый файл** с предсказанными категориями для тестовой выборки.
-   `X_test_fully_with_predictions.csv`: Тестовые данные с предсказаниями и скорами уверенности модели (для анализа).
-   `.gitattributes`: Файл конфигурации Git для работы с большими файлами (Git LFS).
-   `datasets_archive/`: Папка с архивом всех промежуточных и итоговых датасетов, полученных в ходе работы:
    -   `X_train.csv`, `X_test.csv`: Исходные неразмеченные данные.
    -   `saiga_mistral_7b_df_train.csv`: Промежуточные результаты разметки моделью `saiga_mistral`.
    -   `qwen2.5-7B_instruct_df_train_v*.csv`: Промежуточные результаты разметки моделью `Qwen` с разными версиями промпта.
    -   `dataset_*.csv` (dishes, shoes, и т.д.): Синтетически сгенерированные данные для каждой миноритарной категории.
    -   `df_balanced_train.csv`: Итоговый сбалансированный датасет для обучения.
    -   `y_true.csv`, `y_mistral.csv`: Различные версии меток, использовавшиеся для анализа и сравнения (были получены с помощью saiga_mistral на разных этапах работы)
